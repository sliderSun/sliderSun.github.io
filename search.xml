<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[最近的一些思考]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F12%2F15%2F%E6%9C%80%E8%BF%91%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[短暂停留与思考&#160; &#160; &#160; &#160;今天是2018年12月15号，距离小亮上次发文已经过去两个月了，这两个月虽然中间有一次研究生数学考试，但是更多的是时间，而小亮却没有坚持继续与大家分享博客，这是小亮的不足，在此深表歉意，为此立下军令状，以后两天更新一篇博文，等到短暂的研究生职业生涯结束时，那时候再回头看看，这又何不是一笔宝贵的财富呢？ 我是赵小亮，一枚NLP大道上的小白，喜欢用文字记载生活、学习、科研中的事情，因为我觉得文字是有温度的，可以暖化人心，在冰冷枯燥的科研之路上，你我的互相借力，又何尝不是一种结果呢？This is for you! I promise!&#160; &#160; &#160; &#160;AI大餐预告：下周小亮会出一个Attention系列专题，大概有六大板块，从Attention Mechanism的起源、历史、变种、相关论文《Attention Is All You Need》以及实战，还有一些思考，带领大家一起吃Attention这顿大餐！ 一、生活是具体的&#160; &#160; &#160; &#160; 小亮最近虽然没有写技术博客，停滞了两个月，内心无比自责，愧对于各位AI技术爱好者。但是，最近倒是读了一些书籍，不管是不是所谓的心灵鸡汤，我觉得凡事能够促进你积极前进的在这一阶段都是良药，下面小亮就和各位share一些心得体会，愿在这冬日的寒风凛冽中，给予一丝温暖。&#160; &#160; &#160; &#160; 是这样的，小亮最近读的这本书叫《具体生活》，这本书一共有七章，我们今天来分享前三章，后面的小亮会随后附上，这本书是由清华大学吴军老师撰写的（各位如果不知道吴军老师的话，可以百度一下哈！小亮这里给出网址 https://baike.baidu.com/item/吴军/8125425?fr=aladdin） 下面是小亮在读书的时候觉得书中内容写的触动心灵的部分，与君共品之！ 1. 具体生活 不是抽象任性的美好畅想 &#160; &#160; &#160; &#160; 人是矛盾的动物。大部分人会说，工作是为了更好地生活，但实际上，人常会在工作和生活中产生矛盾时，选择放弃生活，而忘记了工作的初衷。每个人的具体生活，都是独一无二的，既不能由别人代替，也不可能在以后的时间补上。生活的风范、品味和认知水平或许能够帮助你，找回真实的自己。 2. 第一章：旅行的意义 &#160; &#160; &#160; &#160; 为什么要旅行？虽然不同的人有不同的看法，但是人们通常会说“行万里路胜于读万卷书。 平心而论，很难讲读万卷书和行万里路哪一个收获更大。不过，行万里路的收获常常是读书、看电视，或者上网学习所得不到的。因此我常常认为读书和旅行的收益是互补的。 3. 第二章：博物馆之美 &#160; &#160; &#160; &#160; 每到一个新的城市，我都会去当地最具有特色的博物馆参观，因为博物馆通常浓缩了一个地方的历史和文化。各地不同的博物馆看得多了，不仅可以体会不同地域人类的文明和生存方式，了解世界各地文化的多样性，而且慢慢地就能够绘制出人类文明的全图。在这一章里面，我们一起来看看在世界上那些著名的博物馆里，有哪些人类的文明足迹和艺术成就。 4. 第三章：读书以怡情长智 &#160; &#160; &#160; &#160; 古人把读万卷书和行万里路看作精英阶层成长不可或缺的两个环节，它们既能使人获取知识、也能令人愉悦自我。今天因为互联网或其他展示形式更丰富的媒体，使得获取知识似乎变得更容易了，那么读书，特别是读纸质书是否还有必要呢？ 答案是肯定的，因为读书的好处远不止获取知识和愉悦自我，它还是我们与世界交流的一种方式，也是我们思想形成的一个环节。 二、修炼内功&#160; &#160; &#160; &#160; “内功”这个词小亮第一次听是跟着导师，第二次是在这里——&gt;《任正非内部讲话曝光：美国不认同我们，我们就把5G做得更好，争取更多的西方客户》(以下内容转载自创财经，非商业等其他用途。)&#160; &#160; &#160; &#160; 近日，任正非一篇最新内部讲话曝光，讲话中理性分析了中国和西方价值观的不同，并表示，只有站在西方的观念上理解西方，才能进得去西方国家。要从人类文明的结晶中，去寻找解决世界问题的钥匙。任正非称，华为员工要多练内功，内功的强大才是真正的强大，抗住外部压力要靠内功。现在社会过分夸大了华为，这是有害的，特别是别让我们的年轻人，以为公司真的成功了，而麻痹起来。华为要将外部环境的压力变成倒逼我们业务创新与管理改进的动力。同时我们不能低估全球权力格局的动态变化，不能盲目自信，那就像100多年前义和团那样了。尽管我们不被个别西方国家认同，不要埋怨，因为我们做得还不够好。美国不认同我们，我们就把5G做得更好，争取更多的西方客户。 &#160; &#160; &#160; &#160;从人类文明的结晶中，找到解决世界问题的钥匙——任正非在公共关系战略纲要汇报会上的讲话_2018年9月29日&#160; &#160; &#160; &#160;一、我们要解决在西方遇到的问题，首先要充分认识西方的价值观，站在他们的立场去理解他们。&#160; &#160; &#160; &#160;二、学点哲学、历史、社会学、心理学、国际法律秩序及权力分配学…….，从中找到解决世界问题的钥匙。公共关系纲要中，哲学、历史、社会学和心理学等都需要放进来，这些人类文明的结晶，会带着我们找到解决世界问题的钥匙。&#160; &#160; &#160; &#160;三、基础研究突破正在结构性深化，我们还没有被产业认同，是因为我们做得还不够好。&#160; &#160; &#160; &#160;四、未来公共关系的价值观与故略纲领是“合作共赢”，要建立一个开放的思想架构。你们是一把伞，可能与业务部门有冲突，各说各的调，唱唱双簧，他们做他们的“矛”，也没有什么不好，没有必要步调一致。合作共赢是公司的大思想，实现过程是困难的，要允许部门不听话，慢慢会转过来的，这就是华为。&#160; &#160; &#160; &#160;五、公共关系要从一个部门，走向一个场态。]]></content>
      <tags>
        <tag>具体生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习Day6]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F10%2F07%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day6%2F</url>
    <content type="text"><![CDATA[Day6逻辑回归之代码实战 一、温习之&#160; &#160; &#160; &#160;上来再把这张逻辑回归的图放在这里，让大家再温习一下逻辑回归的基本概念哈！ 二、介绍之&#160; &#160; &#160; &#160;好，下面开始进入代码实战环节，女士们、先生们，集中注意力啦！先介绍一下今天的数据集(在Machine_Learning领域，数据集很重要，曾经小亮在听讲座的时候有牛人说，Deep_Learning时代是靠数据驱动的，数据就是血液，是宝贵的资源。所以，大家一定要重视数据！)我们选用国外的Social_Network_Ads数据，该数据集包含了社交网络中用户的信息。这些信息涉及 用户ID,性别,年龄以及预估薪资。一家汽车公司刚刚推出了他们新型的豪华SUV，我们尝试预测哪些用户会购买这种全新SUV。并且在最后一列用来表示用户是否购买。我们将建立一种模型来预测用户是否购买这种SUV，该模型基于两个变量，分别是年龄和预计薪资。因此我们的特征矩阵将是这两列。我们尝试寻找用户年龄与预估薪资之间的某种相关性，以及他是否购买SUV的决定。数据结构如下图所示： 三、实践之&#160; &#160; &#160; &#160;好，数据结构介绍完了，我们开始写代码啦！(大家以后写代码一定要养成一个良好的习惯，在写代码之前，一定要分析清楚自己这个程序需要几个步骤step，也就是需要几个模块，每个步骤需要什么库和函数，每一部分之间有什么联系，这个思考很重要！！！小亮本科时的C++老师曾说过：三分写代码，七分调试代码，小亮觉得很有道理，但是小亮想再加一句,优化一下：三分设计代码、三分写代码、四分debug代码！！！是不是很有道理？)我们今天的这个程序主要分为五个大步骤，如下所示：&#160; &#160; &#160; &#160;Step1:数据预处理。&#160; &#160; &#160; &#160;(1)导入相关的python库。我们主要用到numpy、pandas、matplotlib以及sklearn库。&#160; &#160; &#160; &#160;(2)导入数据集，就是我们上面所展示的数据集Social_Network_Ads&#160; &#160; &#160; &#160;(3)将数据集分成训练集和测试集。&#160; &#160; &#160; &#160;(4)特征缩放。&#160; &#160; &#160; &#160;Step2:建立逻辑回归模型。这一步的python库将会是一个线性模型库，之所以被称为线性是因为逻辑回归是一个线性分类器，这意味着我们在二维空间中，我们两类用户（购买和不购买）将被一条直线分割。然后导入逻辑回归类。下一步我们将创建该类的对象，它将作为我们训练集的分类器。&#160; &#160; &#160; &#160;(1)将逻辑回归应用于训练集&#160; &#160; &#160; &#160;Step3:预测。&#160; &#160; &#160; &#160;(1)预测测试集结果。&#160; &#160; &#160; &#160;Step4:评估预测。我们预测了测试集。 现在我们将评估逻辑回归模型是否正确的学习和理解。因此这个混淆矩阵将包含我们模型的正确和错误的预测。&#160; &#160; &#160; &#160;(1)生成混淆矩阵&#160; &#160; &#160; &#160;Step5:调用matplotlib库可视化。 四、结果之&#160; &#160; &#160; &#160;下面就是我们通过对Social_Network_Ads数据集建立逻辑回归产生的结果： 五、代码之&#160; &#160; &#160; &#160;下面就是我们本节内容建立逻辑回归所需要的全部代码： #coding:utf-8 #Step 1:导入库 import numpy as np import matplotlib.pyplot as plt import pandas as pd #Step 2:导入数据集 dataset = pd.read_csv(&apos;Social_Network_Ads.csv&apos;) X = dataset.iloc[:, [2, 3]].values Y = dataset.iloc[:,4].values #Step 3:将数据集分成训练集和测试集 from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0) #Step 4:特征缩放 from sklearn.preprocessing import StandardScaler sc = StandardScaler() X_train = sc.fit_transform(X_train) X_test = sc.transform(X_test) #Step 5:逻辑回归模型,将逻辑回归应用于训练集 from sklearn.linear_model import LogisticRegression classifier = LogisticRegression() classifier.fit(X_train, y_train) #Step 6: 预测,预测测试集结果 y_pred = classifier.predict(X_test) #Step 7:评估预测我们预测了测试集。 生成混淆矩阵 from sklearn.metrics import confusion_matrix cm = confusion_matrix(y_test, y_pred) #Step 8:可视化 from matplotlib.colors import ListedColormap X_set,y_set=X_train,y_train X1,X2=np. meshgrid(np. arange(start=X_set[:,0].min()-1, stop=X_set[:, 0].max()+1, step=0.01), np. arange(start=X_set[:,1].min()-1, stop=X_set[:,1].max()+1, step=0.01)) plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap((&apos;red&apos;, &apos;green&apos;))) plt.xlim(X1.min(),X1.max()) plt.ylim(X2.min(),X2.max()) for i,j in enumerate(np. unique(y_set)): plt.scatter(X_set[y_set==j,0],X_set[y_set==j,1], c = ListedColormap((&apos;red&apos;, &apos;green&apos;))(i), label=j) plt. title(&apos; LOGISTIC(Training set)&apos;) plt. xlabel(&apos; Age&apos;) plt. ylabel(&apos; Estimated Salary&apos;) plt. legend() plt. show() X_set,y_set=X_test,y_test X1,X2=np. meshgrid(np. arange(start=X_set[:,0].min()-1, stop=X_set[:, 0].max()+1, step=0.01), np. arange(start=X_set[:,1].min()-1, stop=X_set[:,1].max()+1, step=0.01)) plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap((&apos;red&apos;, &apos;green&apos;))) plt.xlim(X1.min(),X1.max()) plt.ylim(X2.min(),X2.max()) for i,j in enumerate(np. unique(y_set)): plt.scatter(X_set[y_set==j,0],X_set[y_set==j,1], c = ListedColormap((&apos;red&apos;, &apos;green&apos;))(i), label=j) plt. title(&apos; LOGISTIC(Test set)&apos;) plt. xlabel(&apos; Age&apos;) plt. ylabel(&apos; Estimated Salary&apos;) plt. legend() plt. show()]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习Day5]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F10%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day5%2F</url>
    <content type="text"><![CDATA[Day5逻辑回归之数学原理&#160; &#160; &#160; &#160;在开始枯燥的数学理论之前，小亮在带领大家回顾一下“Logistic_regression”哈，这次以八卦的方式来回味，哈哈。Logistic_regression可以用来回归，也可以用来分类，主要是二分类。大家应该了解点支持向量机SVM吧，(好吧，不了解，没关系哈，后面小亮会总结一下经典的机器学习算法) 其实它就是个二分类的算法，它可以将两个不同类别的样本给分开，思想是找到最能区分它们的那个分类超平面。但当你给一个新的样本给它，它能够给你的只有一个答案，你这个样本是正类还是负类。例如你问SVM，某个女生是否喜欢你，它只会回答你喜欢或者不喜欢。这对我们来说，显得太粗鲁了，要不希望，要不绝望，这都不利于身心健康。那如果它可以告诉你，她很喜欢、有一点喜欢、不怎么喜欢或者一点都不喜欢，你想都不用想了等等，告诉你她有49%的几率喜欢你，总比直接说她不喜欢你，来得温柔。而且还提供了额外的信息，她来到你的身边你有多少希望，你得再努力多少倍，知己知彼百战百胜，哈哈。Logistic_regression就是显得这么温柔，它给我们提供的就是你的这个样本属于正类的可能性是多少。 一、数学原理&#160; &#160; &#160; &#160;数学原理的解读总离不开实例，假设我们的样本是{x, y}，y是0或者1，表示正类或者负类，x是我们的m维的样本特征向量。那么这个样本x属于正类，也就是y=1的“概率”可以通过下面的逻辑函数来表示：这里θ是模型参数，也就是回归系数(这个参数很重要，大家先把它记下来。)，σ是sigmoid函数。实际上这个函数是由下面的对数几率（也就是x属于正类的可能性和负类的可能性的比值的对数）变换得到的：&#160; &#160; &#160; &#160;换句话说，y也就是我们关系的变量，例如她喜不喜欢你，与多个自变量（因素）有关，例如你人品怎样、车子是两个轮的还是四个轮的、长得胜过潘安还是和犀利哥有得一拼、有千尺豪宅还是三寸茅庐等等，我们把这些因素表示为x1, x2,…, xm。那这个女的怎样考量这些因素呢？最快的方式就是把这些因素的得分都加起来，最后得到的和越大，就表示越喜欢。但每个人心里其实都有一杆称，每个人考虑的因素不同，萝卜青菜，各有所爱嘛。例如这个女生更看中你的人品，人品的权值是0.6，不看重你有没有钱，没钱了一起努力奋斗，那么有没有钱的权值是0.001等等。我们将这些对应x1, x2,…, xm的权值叫做回归系数，表达为θ1,θ2,…,θm。他们的加权和就是你的总得分了。请选择你的心仪男生，非诚勿扰！哈哈。 二、再次解读&#160; &#160; &#160; &#160;上面的logistic回归是一个线性分类模型，它与线性回归的不同点在于：为了将线性回归输出的很大范围的数，例如从负无穷到正无穷，压缩到0和1之间，这样的输出值表达为“可能性”才能说服广大民众。当然了，把大值压缩到这个范围还有个很好的好处，就是可以消除特别冒尖的变量的影响（不知道理解的是否正确）。而实现这个伟大的功能其实就只需要平凡一举，也就是在输出加一个logistic函数。对于二分类来说，可以简单的认为：如果样本x属于正类的概率大于0.5，那么就判定它是正类，否则就是负类。实际上，SVM的类概率就是样本到边界的距离，这个活实际上就让logistic regression给做了。 三、神经网络模型&#160; &#160; &#160; &#160;Logistic_regression的神经网络模型如下图所示：(大家不懂这些神经网络基本概念的可以参考小亮之前的博客《神经网络的基本概念》https://blog.csdn.net/jinyuan7708/article/details/82466653) 四、小亮总结&#160; &#160; &#160; &#160;今天我们大概讲了下逻辑回归的数学原理，其实简单点说Logistic_Regression就是一个被logistic方程归一化后的线性回归。最终是用作分类器：从样本集中学习拟合参数，将目标值拟合到[0,1]之间，然后对目标值进行离散化，实现分类，仅此而已。今天的内容掌握了吗？同学们还需要多看看相关的资料哈，下一节小亮带你手撸代码，看看到底什么是Logistic_Regression！！！]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习Day4]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F10%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day4%2F</url>
    <content type="text"><![CDATA[Day4逻辑回归之基本概念&#160; &#160; &#160; &#160;先给大家看一下逻辑回归的基本概念哈，大家先对这个有一个直观的认识就好，看不懂或者不明白没关系哈，后面小亮会一点一点给大家答疑解惑，拨开云雾，柳暗花明哈。逻辑回归如下面这幅图片所示： 一、直观概念&#160; &#160; &#160; &#160;逻辑回归，英文为logistic，又称logistic回归分析，是一种广义的线性回归分析模型，常用于数据挖掘，疾病自动诊断，经济预测等领域。例如，以胃癌病情分析为例，选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群必定具有不同的体征与生活方式等。因此因变量就为是否胃癌，值为“是”或“否”，自变量就可以包括很多了，如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。然后通过logistic回归分析，可以得到自变量的权重，从而可以大致了解到底哪些因素是胃癌的危险因素。同时根据该权值可以根据危险因素预测一个人患癌症的可能性。 二、数学概念&#160; &#160; &#160; &#160;logistic回归是一种广义线性回归（generalized linear model），因此与多重线性回归分析有很多相同之处。它们的数学模型形式基本上相同，都具有 w‘x+b，其中w和b是待求参数，其区别在于他们的因变量不同，多重线性回归直接将w‘x+b作为因变量，即y =w‘x+b，而logistic回归则通过函数L将w‘x+b对应一个隐状态p，p =L(w‘x+b),然后根据p 与1-p的大小决定因变量的值。如果L是logistic函数，就是logistic回归，如果L是多项式函数就是多项式回归 三、小亮总结&#160; &#160; &#160; &#160;逻辑回归其实就是这样的一个过程：面对一个回归或者分类问题，建立代价函数，然后通过优化方法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。Logistic回归虽然名字里带“回归”，但是它实际上是一种分类方法，主要用于两分类问题（即输出只有两种，分别代表两个类别）回归模型中，y是一个定性变量，比如y=0或1，logistic方法主要应用于研究某些事件发生的概率。 四、常用的logistic函数&#160; &#160; &#160; &#160;sigmoid函数为常用的logistic函数，数学公式如下图所示：&#160; &#160; &#160; &#160;小亮再用代码给大家画一下这个函数： #coding:utf-8 import matplotlib.pyplot as plt import numpy as np def Sigmoid(x): return 1.0 / (1.0 + np.exp(-x)) x = np.arange(-20, 20, 0.1) h = Sigmoid(x) # Sigmoid函数 plt.plot(x, h,color=&apos;red&apos;) plt.axvline(0.0, color=&apos;k&apos;) # 坐标轴上加一条竖直的线（0位置） plt.axhspan(0.0, 1.0, facecolor=&apos;1.0&apos;, alpha=1.0, ls=&apos;dotted&apos;) plt.axhline(y=0.5, ls=&apos;dotted&apos;, color=&apos;k&apos;) plt.yticks([0.0, 0.5, 1.0]) # y轴标度 plt.ylim(-0.1, 1.1) # y轴范围 plt.show()]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018知识图谱发展报告之小亮见解]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F10%2F02%2F2018%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%8F%91%E5%B1%95%E6%8A%A5%E5%91%8A%E4%B9%8B%E5%B0%8F%E4%BA%AE%E8%A7%81%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[2018知识图谱发展报告之小亮见解&#160; &#160; &#160; &#160;先给大家把此次2018知识图谱的发展报告PDF版送上，封面如下面这幅图片所示：百度云链接为：链接：https://pan.baidu.com/s/1qI7pYp03NOTL4V9cQ9GV2g 密码：kewf&#160; &#160; &#160; &#160;下面是这份知识图谱的目录和编写人员，可以看到大多数是领域内知名专家和教授，比如小亮目前所在的事件检测方向的赵军老师和他的学生陈玉博老师等等。&#160; &#160; &#160; &#160;小亮对这份知识图谱领域的发展报告大致看了一遍，其中对于第五章《事件知识学习》看的比较详细，因为目前小亮对这个领域内的任务比较明确，下面就讲讲小亮之所见吧。&#160; &#160; &#160; &#160;事件识别和抽取研究如何从描述事件信息的文本中识别并抽取出事件信息并以结构化的形式呈现出来，包括其发生的时间、地点、参与角色以及与之相关的动作或者状态的改变，核心的概念如下图所示：&#160; &#160; &#160; &#160;事件检测与追踪旨在将文本新闻流按照其报道的事件进行组织，为传统媒体多种来源的新闻监控提供核心技术，以便让用户了解新闻及其发展。具体而言，事件发现与跟踪包括三个主要任务：分割，发现和跟踪，将新闻文本分解为事件，发现新的（不可预见的）事件，并跟踪以前报道事件的发展。事件发现任务又可细分为历史事件发现和在线事件发现两种形式，前者目标是从按时间排序的新闻文档中发现以前没有识别的事件，后者则是从实时新闻流中实时发现新的事件。 数据集&#160; &#160; &#160; &#160;现在不论是自然语言处理领域，还是计算机视觉领域，都热衷于神经网络Embedding方法，自然少不了对于数据集的选取。那么，Event Detection领域的标准数据集是ACE2005语料。详细的语料介绍如下所示：&#160; &#160; &#160; &#160;ACE语料是需要花钱买的，现在网上是找不到免费的语料的。出于对中文事件语料Chinese Event Corpus, CEC的好奇，小亮找到了这个语料(大家如果做研究用，可以免费下载哈！)： 链接如下：https://github.com/shijiebei2009/CEC-Corpus&#160; &#160; &#160; &#160;中文突发事件语料库是由上海大学（语义智能实验室）所构建。根据国务院颁布的《国家突发公共事件总体应急预案》的分类体系，从互联网上收集了5类（地震、火灾、交通事故、恐怖袭击和食物中毒）突发事件的新闻报道作为生语料，然后再对生语料进行文本预处理、文本分析、事件标注以及一致性检查等处理，最后将标注结果保存到语料库中，CEC合计332篇。 技术路线&#160; &#160; &#160; &#160;事件抽取当前技术路线为基于模识匹配的事件抽取和基于机器学习的事件抽取。其中，基于模识匹配的事件抽取是基于传统的方法来做，需要定义模式和规则，比较严谨，在特定领域中性能较好，表示简洁，但对于语言、领域和文档形式等均有不同程度的依赖，覆盖度和可移植性较差。基于机器学习的方法建立在统计模型基础上，一般将事件抽取建模成多分类问题，因此研究的重点在于特征和分类器的选择。这块将局部信息与全局信息的融合思想，小亮觉得可以重点研究一下可行性问题和性能，这个idea还是不错的。 机遇与挑战&#160; &#160; &#160; &#160;目前国内外事件抽取相关的研究大部分都是面向英文文本的英文事件抽取，面向中文文本的中文事件抽取工作才刚刚起步，主要面临技术和数据两方面的挑战。技术层面，中文的词句是意合的，词语间没有显式分隔符，而且中文实词在时态和形态上也没有明显变化， 因此面向中文的事件抽取研究在基础自然语言处理层面具有天然的劣势。 数据层面， 由于起步较晚，缺乏统一的、公认的语料资源和相关评测，极大制约了中文事件抽取的研究。尽管如此，近些年中文事件抽取在公开评测、领域扩展和跨预料迁移方面也取得一定进展。所以，小亮觉得，中文场景下的事件抽取拥有更大的发展潜力与空间，以后小亮还会持续关注这个了领域的。 小亮说&#160; &#160; &#160; &#160;最后，小亮觉得知识图谱也是这两年一下就火起来了，还处于一个萌芽的阶段，对这个领域的技术小亮心里还抱有迟疑的感觉，不过未来知识图谱的发展一定是空前的，可能三五年后吧，知识图谱将会改变传统的搜索引擎的模式，领域内知识图谱会更多，更成熟，这也是一个非常好的机会。明天或者后天小亮会实践一下知识图谱这个领域的技术，切身感受一下它的威力。以上就是小亮对于2018年知识图谱发展报告的一个小小的感受，欢迎大家交流哈！]]></content>
      <categories>
        <category>自然语言处理 知识图谱 Knowledge_Graph</category>
      </categories>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习Day3]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F30%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day3%2F</url>
    <content type="text"><![CDATA[Day3多元线性回归&#160; &#160; &#160; &#160;先给大家看一下这一部分的流程哈，主要分为3个Step，如下面这幅图片所示： #coding:utf-8 # 导入库 import pandas as pd import numpy as np #Step1: 导入数据集 dataset = pd.read_csv(‘50_Startups.csv’) X = dataset.iloc[ : , :-1].values Y = dataset.iloc[ : , 4 ].values # Step2: 将类别数据数字化 from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder = LabelEncoder() X[: , 3] = labelencoder.fit_transform(X[ : , 3]) onehotencoder = OneHotEncoder(categorical_features = [3]) X = onehotencoder.fit_transform(X).toarray() #Step3:躲避虚拟变量陷阱 X = X[: , 1:] # 拆分数据集为训练集和测试集 from sklearn.model_selection import train_test_split X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0) # 第2步： 在训练集上训练多元线性回归模型 from sklearn.linear_model import LinearRegression regressor = LinearRegression() regressor.fit(X_train, Y_train) # Step4: 在测试集上预测结果 y_pred = regressor.predict(X_test) print(y_pred)测试集上预测结果]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习Day2]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F28%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day2%2F</url>
    <content type="text"><![CDATA[Day2简单线性回归&#160; &#160; &#160; &#160;先给大家看一下这一部分的流程哈，主要分为4个Step，如下面这幅图片所示： #coding:utf-8 import pandas as pd import numpy as np import matplotlib.pyplot as plt #Step1:数据预处理 dataset = pd.read_csv(‘studentscores.csv’) X = dataset.iloc[ : , : 1 ].values Y = dataset.iloc[ : , 1 ].values from sklearn.model_selection import train_test_split X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 1/4, random_state = 0) #Step2:训练集使用简单线性回归模型来训练 from sklearn.linear_model import LinearRegression regressor = LinearRegression() regressor = regressor.fit(X_train, Y_train) #Step3：预测结果 Y_pred = regressor.predict(X_test) #Step4:可视化 #训练集结果可视化 plt.scatter(X_train , Y_train, color = ‘red’) plt.plot(X_train , regressor.predict(X_train), color =’blue’) plt.show() #测试集结果可视化 plt.scatter(X_test , Y_test, color = ‘red’) plt.plot(X_test , regressor.predict(X_test), color =’blue’) plt.show()&#160; &#160; &#160; &#160;将上面的代码输入到编辑器中，执行，就会得到下面的结果，因为我们调用Matplotlib画图函数，所以我们可以得到可视化之后的结果，如下图所示：。训练集结果可视化测试集结果可视化]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习Day1]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day1%2F</url>
    <content type="text"><![CDATA[Day1数据预处理&#160; &#160; &#160; &#160;先给大家看一下这一部分的流程哈，主要分为6个Step，如下面这幅图片所示： #coding:utf-8 #Day 1: Data Prepocessing #Step 1: Importing the libraries import numpy as np import pandas as pd #Step 2: Importing dataset dataset = pd.read_csv(&apos;Data.csv&apos;) X = dataset.iloc[ : , :-1].values Y = dataset.iloc[ : , 3].values print(&quot;Step 2: Importing dataset&quot;) print(&quot;X&quot;) print(X) print(&quot;Y&quot;) print(Y) #Step 3: Handling the missing data from sklearn.preprocessing import Imputer imputer = Imputer(missing_values = &quot;NaN&quot;, strategy = &quot;mean&quot;, axis = 0) imputer = imputer.fit(X[ : , 1:3]) X[ : , 1:3] = imputer.transform(X[ : , 1:3]) print(&quot;---------------------&quot;) print(&quot;Step 3: Handling the missing data&quot;) print(&quot;step2&quot;) print(&quot;X&quot;) print(X) #Step 4: Encoding categorical data from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder_X = LabelEncoder() X[ : , 0] = labelencoder_X.fit_transform(X[ : , 0]) #Creating a dummy variable onehotencoder = OneHotEncoder(categorical_features = [0]) X = onehotencoder.fit_transform(X).toarray() labelencoder_Y = LabelEncoder() Y = labelencoder_Y.fit_transform(Y) print(&quot;---------------------&quot;) print(&quot;Step 4: Encoding categorical data&quot;) print(&quot;X&quot;) print(X) print(&quot;Y&quot;) print(Y) #Step 5: Splitting the datasets into training sets and Test sets from sklearn.model_selection import train_test_split X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0) print(&quot;---------------------&quot;) print(&quot;Step 5: Splitting the datasets into training sets and Test sets&quot;) print(&quot;X_train&quot;) print(X_train) print(&quot;X_test&quot;) print(X_test) print(&quot;Y_train&quot;) print(Y_train) print(&quot;Y_test&quot;) print(Y_test) #Step 6: Feature Scaling from sklearn.preprocessing import StandardScaler sc_X = StandardScaler() X_train = sc_X.fit_transform(X_train) X_test = sc_X.transform(X_test) print(&quot;---------------------&quot;) print(&quot;Step 6: Feature Scaling&quot;) print(&quot;X_train&quot;) print(X_train) print(&quot;X_test&quot;) print(X_test) &#160; &#160; &#160; &#160;将上面的代码输入到编辑器中，执行，就会得到下面的结果，大家先看看结果是不是和小亮一样哈，后面我们再解说一下数据处理的详细过程。 G:\Code\Python_Learn\Study_Tensorflow_2018\venv\Scripts\python.exe &quot;G:/Code/Python_Learn/Study_Tensorflow_2018/venv/Machine Learning 100 days/day1/day1.py&quot; Step 2: Importing dataset X [[&apos;France&apos; 44.0 72000.0] [&apos;Spain&apos; 27.0 48000.0] [&apos;Germany&apos; 30.0 54000.0] [&apos;Spain&apos; 38.0 61000.0] [&apos;Germany&apos; 40.0 nan] [&apos;France&apos; 35.0 58000.0] [&apos;Spain&apos; nan 52000.0] [&apos;France&apos; 48.0 79000.0] [&apos;Germany&apos; 50.0 83000.0] [&apos;France&apos; 37.0 67000.0]] Y [&apos;No&apos; &apos;Yes&apos; &apos;No&apos; &apos;No&apos; &apos;Yes&apos; &apos;Yes&apos; &apos;No&apos; &apos;Yes&apos; &apos;No&apos; &apos;Yes&apos;] --------------------- Step 3: Handling the missing data step2 X [[&apos;France&apos; 44.0 72000.0] [&apos;Spain&apos; 27.0 48000.0] [&apos;Germany&apos; 30.0 54000.0] [&apos;Spain&apos; 38.0 61000.0] [&apos;Germany&apos; 40.0 63777.77777777778] [&apos;France&apos; 35.0 58000.0] [&apos;Spain&apos; 38.77777777777778 52000.0] [&apos;France&apos; 48.0 79000.0] [&apos;Germany&apos; 50.0 83000.0] [&apos;France&apos; 37.0 67000.0]] --------------------- Step 4: Encoding categorical data X [[1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01 7.20000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01 4.80000000e+04] [0.00000000e+00 1.00000000e+00 0.00000000e+00 3.00000000e+01 5.40000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01 6.10000000e+04] [0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01 6.37777778e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01 5.80000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01 5.20000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01 7.90000000e+04] [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.00000000e+01 8.30000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01 6.70000000e+04]] Y [0 1 0 0 1 1 0 1 0 1] --------------------- Step 5: Splitting the datasets into training sets and Test sets X_train [[0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01 6.37777778e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01 6.70000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01 4.80000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01 5.20000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01 7.90000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01 6.10000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01 7.20000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01 5.80000000e+04]] X_test [[0.0e+00 1.0e+00 0.0e+00 3.0e+01 5.4e+04] [0.0e+00 1.0e+00 0.0e+00 5.0e+01 8.3e+04]] Y_train [1 1 1 0 1 0 0 1] Y_test [0 0] --------------------- Step 6: Feature Scaling X_train [[-1. 2.64575131 -0.77459667 0.26306757 0.12381479] [ 1. -0.37796447 -0.77459667 -0.25350148 0.46175632] [-1. -0.37796447 1.29099445 -1.97539832 -1.53093341] [-1. -0.37796447 1.29099445 0.05261351 -1.11141978] [ 1. -0.37796447 -0.77459667 1.64058505 1.7202972 ] [-1. -0.37796447 1.29099445 -0.0813118 -0.16751412] [ 1. -0.37796447 -0.77459667 0.95182631 0.98614835] [ 1. -0.37796447 -0.77459667 -0.59788085 -0.48214934]] X_test [[-1. 2.64575131 -0.77459667 -1.45882927 -0.90166297] [-1. 2.64575131 -0.77459667 1.98496442 2.13981082]] Process finished with exit code 0 &#160; &#160; &#160; &#160;上面就是今天的机器学习Day1的内容，大家重点了解一下Numpy、Pandas、Sklearn这三个库的使用和数据处理部分。]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习100天]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0100%E5%A4%A9%2F</url>
    <content type="text"><![CDATA[机器学习100天&#160; &#160; &#160; &#160;小亮接触深度学习也将近一年了，通过走了这么多的路，读论文也好，看视频也好，看书也好，发现还是得通过边敲代码边思考边理解公式这样的方式比较踏实，不然就是天马行空，吹吹牛罢了！你会什么？我会深度学习耶！那你给我写两行代码解决一下这个问题？感知机是什么？交叉熵损失函数是什么？反向转播算法来推导一下？Pandas、Numpy、Scikit-learn这些库用过吗？当面试官或者HR问起这些的时候，我希望小亮或者你们能够胸有成竹的说，这些我都会哈，来我给你手工推导一下交叉熵损失函数是如何影响网络的学习速率的，反向传播算法是根据微积分的链式求导罚则调节参数权重w和偏置b的，这个项目我做过，那个我也知道。。。。。。其实，这个时候这种状态才是小亮应有的状态，希望在2020年毕业的时候，再回到此处时，可以做到无悔于时间、无悔于现在所做的一切与努力。每天进步一点点，来跟着小亮Machine Learning吧！&#160; &#160; &#160; &#160;上面的是机器学习100天的每天的内容，从今天开始，小亮将会身体力行的实践，边思考边前行边总结边记录每一天的成长与收获！欢迎各位小伙伴与小亮一起前行，不断地打怪升级！]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP事件检测基本概念]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F25%2FNLP%E4%BA%8B%E4%BB%B6%E6%A3%80%E6%B5%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[自然语言处理之事件检测一、什么是NLP&#160; &#160; &#160; &#160;nlp是自然语言处理，是电脑理解并表达出人们平常的所说的语言二、nlp的事件抽取是什么？&#160; &#160; &#160; &#160;事件抽取是从非结构信息中抽取出用户感兴趣的信息，并以结构化数据传递给用户。三、事件抽取所处的位置？&#160; &#160; &#160; &#160;事件抽取是信息抽取的一部分。事件抽取的又分为元事件抽取和主题事件抽取。元事件抽取是动作状态级的，动作产生或状态发生变化，一般由动词驱动。主题事件抽取是事件级的，一类核心事件或活动以及与他们相关的事件和活动。四、事件抽取的研究方法有哪些？&#160; &#160; &#160; &#160;事件抽取的研究方法有模式匹配和机器学习两种。模式匹配只针对特定领域，移植性差。机器学习应用广泛，移植性好。五、模式匹配方法如何进行事件抽取？&#160; &#160; &#160; &#160;模式匹配方法是在一定模式的指导下进行事件的识别和抽取。模式：指的是抽取模式。通过领域知识和语言知识对目标信息的上下文环境进行约束。而这约束条件就是抽取模式。另外模式是手工建立的，耗时又费力，所以现在用的都是机器学习方法的事件抽取。六、机器学习方法如何进行事件抽取？&#160; &#160; &#160; &#160;对元事件抽取两大主要任务：对事件识别与分类和对事件元素进行识别和分类。事件元素识别和分类是事件识别和分类的基础。有关论文显示：机器学习算法混合使用将优于单一算法。事件的探测分两种实现方式：基于触发词的探测方式和基于事件的事例的探测方式。&#160; &#160; &#160; &#160;基于触发词的探测方式：&#160; &#160; &#160; &#160;基于触发词的探测方式的有正反例不平衡和数据稀疏的缺点。因为只有少量触发词作为输入数据进行训练，大量未参与进来的。作为反例数据参与到模型中，造成正反例不平衡，触发词数据稀疏。解决触发词探测缺点的方法：通过同义词扩展和二分类结合的方法进行解决，即将触发词放入词典中进行同义词扩展。&#160; &#160; &#160; &#160;基于事件实例的探测方式：&#160; &#160; &#160; &#160;基于事件实例的探测方式是将句子而不是词语作为识别实例。进而通过聚类方法转化为句子聚类问题，通过聚类得到事件句。避开了基于触发词探测的缺点。七、基于机器学习方法抽取方式的特点？&#160; &#160; &#160; &#160;(1) 机器学习方法的优点是自动获取模式。&#160; &#160; &#160; &#160;(2) 机器学习方法不基于语料的格式和内容，但需要大量标准预料（解决方法:无监督和半监督的方法）]]></content>
      <categories>
        <category>NLP Event Detection</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这里的人与这里的故事]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F09%2F%E8%BF%99%E9%87%8C%E7%9A%84%E4%BA%BA%E4%B8%8E%E8%BF%99%E9%87%8C%E7%9A%84%E6%95%85%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[&#160; &#160; &#160; &#160;在记录自己今天的感受前，先来介绍一下我大学仅有的几个好朋友之一———&gt;老郭（也就是今天的主人公李同学）！我和老郭的认识源于电子设计比赛，认知于电子设计比赛，结交于电子设计比赛，虽然我们不是一个班的，但是我们在很多问题上交流的很多，从他身上也学到了很多为人处世的道理——&gt;谦逊、踏实、担当，还有感恩！&#160; &#160; &#160; &#160;早上十点钟我们本来约定在大学城地铁站见面，但是很巧的是，在营口道转3号线的时候，小亮竟然与老郭完美的偶遇于一趟车的相邻车厢。（这就是缘分！哈哈！）上车后第一眼就看到了他，远远地看去，瘦了一圈，可能是来自于工作的压力人就会瘦吧！身穿一件深灰色的衬衣与牛仔裤，戴着耳机，（程序员可能都是这样的装备吧！）也在寻觅着我。老郭还是老郭，还是那样的幽默风趣，还是那样的思考着前行着前行着而又思考着，其实小亮心里一直挺为他惋惜的，但是一直又鼓励着他，让他自信起来，相信自己，不要因为过去的事带着自卑的情绪而影响现在的自己，因为你值得更好地未来，没错，你值得！！！我们俩就像失散多年的老友一样，还是当年的那个老郭与于谦，相谈甚欢。&#160; &#160; &#160; &#160;到了大学城地铁站，我建议骑个小黄去学院吧，老郭说咱们走过去吧，我说好，这样也可以用脚步重新再走一遍这个地方。于是，我们就顶着今天的太阳，感受着校庆60周年的余热，北门的一句“欢迎校友回家”甚是暖心，是啊，才毕业不到三个月的我们，已然是这所大学的校友，感叹时间过得如此的飞快，老郭突然冒出一句：“下一次回到这里就不知道是什么时候了，或许在十年后吧！”我紧接着附和道：“是啊，可能是十年后了吧！”之所以与老郭的关系不断深入，就是因为知道他的每一句话背后的故事，以及他在想什么，而他所想的同时也是我想的，或许这就是我们能够说到一块的原因吧。此刻，他又在感叹，感叹曾经的故事！走在宽大的校园马路上，随处可见工大60周年校庆的牌子，还挺美的，与大家分享一下哈！&#160; &#160; &#160; &#160;走到这里的时候，突然有三四个中年阿姨，问我们：“同学，你知道校史馆怎么走吗？”我和老郭给这些校友前辈指了校史馆的位置，老郭说要不咱们也去看看吧，之前我没去过，我说好。就这样，我们作为年轻校友在前面给校友前辈带路，到了校史馆，我和老郭在前面观看学校的历史与珍贵的仪器，顺便听讲着学生讲解员给她们的讲解。在走到一台上了年纪的纺织仪器面前，老郭出于一贯的质疑与好奇思维，尝试着搞明白它的机械原理（被我偷拍了，哈哈）&#160; &#160; &#160; &#160;还有这个—————&gt;&#160; &#160; &#160; &#160;在经过时间里程计的时候，我突然握住老郭的大手，我说一起见证这伟大的时刻吧，而老郭突然配乐道：“当当当当。。。。。。”我禁不住笑了起来，你这是瓦格纳的《婚礼进行曲》啊，有点尴尬，哈哈。&#160; &#160; &#160; &#160;参观完校史馆，我们迫不及待的赶紧前往学院，先去了老师办公室，结果发现没人，可能是周末的原因吧。。。。。。。。然后我们就去考研自习室找了会煜大神，时间也十一点了，我们商量着要不先去吃饭去吧，就边走边聊，老郭和会煜大神谈起来更是津津有味，他们两更是同道中人。（这次回来，发现大家都没怎么变，还是老样子，真切、幽默、调侃、又互相关心着彼此的发展，或许这就是好朋友最真的面貌吧！）吃饭回来在学院一楼又聊了聊，聊到了过去，聊到了现在，还聊到了未来。&#160; &#160; &#160; &#160;聊到了大概十二点半左右，我和老郭看着时间也不早了，不能影响了会煜大神的节奏，我们就与他告别离开了，希望今年他能够考上自己心仪的学校，也是我们专业，甚至学院最有希望与能力的。其实，自己从他那里也学到了很多很多，做事态度认真，求真务实、追求完美、说话只说自己很有把握的话，给人一种非常踏实的感觉与印象，就是每一件事都交给他，让人很放心，而且他不仅会完成任务，而且还会给你优化与一些建议，这就是他，会煜大神，关于他的故事已然成为我们专业，乃至学院的神话，人人皆知，人人皆视其为榜样！&#160; &#160; &#160; &#160;再后来，我和老郭联系了一下老师，老师说他刚到办公室，我们去办公室找他，就这样，我和老郭准备了半个小时就去看望老师了。和老师谈了两三个小时，谈到了过去，谈到了现在，谈到了未来。谈到了学业、谈到了工作、谈到了个人理想。老郭又有些感触了，(我总觉得他有些不甘心，有些自卑)老师似乎也发现了，就鼓励他说其实做技术积累个两三年也挺好的，现在的研究生动手能力太差了，连最基本的仪器都不会使用，到时候找工作就不如你们这些已经工作了两三年的，只是他们起点比你们现在高罢了，老郭听后觉得也有道理，目光些许明亮起来，给老师说，他有这个自信能够在单位里做好。（以老郭的能力与思维能力，我相信三五年后，或许我该叫他李所或者李部长了。）后来又和老师聊了很多，老师也相应的给了一些建议，让我们不管在社会上还是学校里，都要实事求是，踏踏实实做技术，规划好自己的时间与人生，该来的总会来的，要懂得隐忍与坚守！！！&#160; &#160; &#160; &#160;四点左右，我和老郭看着时间不早了，也不想打扰老师工作（周末老师还来实验室，可见他的敬业与乐业精神所在）我们就和老师道别后，离开了。&#160; &#160; &#160; &#160;最后想说，自己虽然现在已是一名研究生了，两年半后自己也面临着找工作，进入社会这个象牙塔，到时候是以怎样的姿态以及怎样的精神面貌迎接那时候的社会与工作，全在这不到三年里的每一天的进步与成长，就像老郭一样，思考着前行着前行着而又思考着，生活就是这样。人生路上能够遇到这样的恩师很难得，也很庆幸自己能够在求学路上遇见很多这样的恩师，古语云：“十年树木，百年树人；插柳之恩；终生难忘！”最后，明天是教师节，提前预祝天下的所有教师节日快乐！ ——2018年9月9日夜晚 于天津大学北洋园]]></content>
      <categories>
        <category>朋友 人生导师</category>
      </categories>
      <tags>
        <tag>人生路上的朋友</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算图上的微积分：反向传播]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F05%2F%E8%AE%A1%E7%AE%97%E5%9B%BE%E4%B8%8A%E7%9A%84%E5%BE%AE%E7%A7%AF%E5%88%86%EF%BC%9A%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%2F</url>
    <content type="text"><![CDATA[一、介绍反向传播是一种关键的算法，它可以使训练深度模型在计算上易于处理。对于现代神经网络来说，相对于一个简单的实现，它可以使梯度下降的训练速度达到1000万倍。这就是一周训练和用20万年时间训练的模型之间的区别。除了在深度学习中使用之外，反向传播在许多其他领域是一个强大的计算工具，从天气预报到分析数字稳定性，它只是在不同的领域用不同的名字。事实上，该算法在不同的领域至少被重新改造了几十次（见Griewank（2010））。一般，应用程序独立，名称是“反向模式区分”。从根本上说，这是一种快速计算微分的技术。在你的包里，这是一个很重要的技巧，不仅在深度学习中，而且在各种各样的数字计算环境中。二、计算图计算图是一种思考数学表达式的好方法。例如，考虑表达式e =(a + b)∗(b + 1)。这里有三个操作：两个加法和一个乘法。为了帮助我们讨论这个问题，让我们引入两个中间变量，c和d，所以每个函数的输出都有一个变量。我们现在有: c=a + b d=b + 1 e=c * d为了创建一个计算图，我们将这些操作连同输入变量一起放入节点。当一个节点的值是另一个节点的输入时，一个箭头从一个节点到另一个节点。在计算机科学中，这些图表一直都在出现，尤其是在谈论功能程序的时候。它们与依赖关系图和调用图的概念密切相关。它们也是流行的深度学习框架Theano背后的核心抽象。我们可以通过将输入变量设置为特定的值和通过图表计算节点来评估表达式。例如,让我们设置a = 2和b = 1 :表达式的求值结果为6。三、计算图的导数如果想要在计算图中理解导数，关键是要理解导数的边界。如果a直接影响c，然后我们想知道它是如何影响的c。如果a稍微改变一下，那c如何改变?我们称其c是关于a的偏导数。为了求出这张图中的偏导数，我们需要求和规则和乘积法则：下图中每条边都有导数。如果我们想要了解没有直接连接的节点是如何相互影响的呢？让我们考虑一下e是如何被a影响的。如果我们以1的速度改变a，c同样的变化速度1改变。反过来, c以1的速度变化导致e以2的改变速率。所以e变化速率1∗2关于a。一般规则是对从一个节点到另一个节点的所有可能路径求和，将路径的每个边的导数相乘。例如，要得到e关于b的导数。我们得到:这就解释了b是如何影响e到c的，以及它是如何通过d来影响它的。这种一般的“对路径求和”规则只是一种不同的关于多元链式法则的思考方式。四、因式分解路径仅仅“对路径求和”的问题是，在可能的路径中，很容易得到一个组合爆炸。在上面的图中，从X到Y有三条路径，从Y到Z还有三条路径。如果我们想求导∂Z/∂X的话，通过对所有路径求和，我们需要求和3∗3 = 9条道路:上面只有9条路径，但是当图形变得更加复杂时，很容易就会有成倍增长的路径。与其简单地对路径求和，不如把它们因式分解：这就是“前向传播”和“反向传播”。它们是通过分解路径来有效计算总和的算法。它们不是显式地对所有路径求和，而是通过在每个节点上合并路径来更有效地计算相同的总和。事实上，这两种算法都能精确地触碰到每条边！ 前向传播从图的输入开始，然后向末端移动。在每个节点上，它都能计算出所有的路径。每条路径都代表了输入影响该节点的一种方式。通过把它们加起来，我们得到了节点受输入影响的总方式，它是导数。虽然你可能没有从图的角度来考虑它，但是向前模式的微分和你在微积分课上做过的介绍是非常相似的。另一方面，反向传播的微分，从图的输出开始，向开始移动。在每个节点上，它合并了源自该节点的所有路径。前向传播微分研究一个输入如何影响每个节点。反向传播微分研究每个节点如何影响一个输出。也就是说，正向模式微分应用算子∂/∂X对每个节点，反向模式微分应用算子∂Z/∂每一个节点。五、Computational Victories在这一点上，您可能想知道为什么有人会关心反向传播的微分。这看起来像是一种奇怪的方法，可以做与前模一样的事情。有什么好处吗？让我们再来看看我们最初的例子：我们可以使用正向模式的微分b向上，这就给了我们每个结点的导数b。我们计算∂e/∂b，这个导数是我们的输出对我们的输入的导数。如果我们做反向模式的微分从e开始? 这就得到了e对于每个节点的微分。当我说反向传播微分给我们对每个结点的导数时，我确实是指每个结点。我们得到两个∂e/∂a和∂e/∂b，e的导数是关于两个输入。前向传播的微分给了我们输出对单个输入的导数，但是反向模式的微分给了我们所有的结果。对于这个图，这只是两个因子的加速，但是想象一个有上百万个输入和一个输出的函数。前向传播的微分要求我们通过这个图上百万次来得到导数。反向传播的微分可以一下子把它们都弄到手！一个百万分之一的速度是相当不错的！在训练神经网络时，我们考虑的是成本（描述神经网络的糟糕程度）作为参数的函数（描述网络行为的数字）。我们想要计算所有参数的成本的导数，用于梯度下降。现在，在神经网络中，通常有数百万甚至数千万个参数。所以，反向模式的分化，在神经网络的背景下被称为反向传播，给我们一个巨大的速度！（有任何情况下，正向模式的分化更有意义吗？是的,有! 当反向模式给出一个输出对所有输入的导数时，正向模式给出了所有输出对一个输入的导数。如果一个函数有大量的输出，那么正向模式的微分就会大大加快。)六、这不是简单的吗?Isn’t This Trivial?当我第一次理解反向传播的时候，我的反应是：“哦，这就是链式法则！我们怎么花了这么长时间才弄明白？“我不是唯一一个有这种反应的人。”的确，如果你问“在前馈神经网络中有一种聪明的计算导数的方法吗？”“答案并不难。但我认为这比表面上看起来要困难得多。你看，在反向传播发明的时候，人们并不是很关注我们研究的前馈神经网络。同样不明显的是，微分是培训它们的正确方式。一旦你意识到你可以快速计算出导数，这些就很明显了。这是一种循环依赖。更糟糕的是，在不经意的想法中，把循环依赖的任何部分都写下来是很容易的。用微分工具训练神经网络？你肯定会被困在局部最优解里。很明显，计算所有这些导数都很昂贵。这只是因为我们知道这种方法是有效的，我们不会立即开始列出它可能不会的原因。这是事后诸葛亮的好处。一旦你提出了这个问题，最困难的工作就已经完成了。七、结论微分比你想象的要便宜。这是我们从这篇文章中得到的主要教训。事实上，它们的价格并不便宜，而美国愚蠢的人不得不反复发现这一事实。在深度学习中，这是很重要的一点。在其他领域中，这也是一件非常有用的事情，只有当它不是常识的时候才会知道。还有其他的教训吗？我认为有。反向传播也是理解微分如何流经模型的有用工具。这对于解释为什么有些模型很难优化是非常有用的。最典型的例子是在重复的神经网络中消失的梯度问题。最后，我认为从这些技术中可以得到一个广泛的算法教训。反向传播和正向模式的区别使用强大的一对技巧（线性化和动态规划）来比人们想象的更有效地计算导数。如果您真正理解了这些技术，您可以使用它们来有效地计算其他涉及到微分的有趣表达式。我们将在以后的博客文章中探讨这个问题。这篇文章给出了一个非常抽象的反向传播的方法。我强烈建议阅读Michael Nielsen关于它的章节，进行精彩的讨论，更具体地关注神经网络。八、致谢感谢Greg Corrado，Jon Shlens，Samy Bengio和an利亚Angelova，感谢他们花时间校对这篇文章。也要感谢达里奥阿米迪、迈克尔尼尔森和约书亚本吉奥讨论解释反向传播的方法。也要感谢那些在演讲和研讨会系列中允许我练习解释反向传播的人！]]></content>
      <categories>
        <category>计算图 神经网络</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再谈数据结构]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F05%2F%E5%86%8D%E8%B0%88%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[我把书籍PDF版本和配套代码放在我的百度云里，附上链接地址：百度云链接：https://pan.baidu.com/s/1dp9K-KljcZoctUL37yCvWg 密码：43po小亮的同学（栗同学）在大学和小亮是一个专业的，研究生申请到了法国格勒诺布尔大学，（很优秀哈）。先介绍一下这个大学哈：格勒诺布尔大学集团（格勒诺布尔-阿尔卑斯大学）是一所拥有近七百年历史的国立研究型大学，其科研实力处于法国顶尖水平，诞生过两位诺贝尔奖获得者（克劳斯·冯·克利青Klaus von Klitzing，路易·奈尔Louis Néel），一位图灵奖获得者（Joseph Sifakis），同时也是联合国教科文组织国际传播学教席（Chaire UNESCO）所在处。院校声誉：具有世界影响力的法国顶尖大学优势专业：自然科学、医学、社会与人文科学、语言学、信息传播学中国教育部是否认证：获得认证全球排名：CWUR（2018）世界大学排名第97位 USNews世界大学排名 （2018）全球大学排名第146位ARWU （2017）世界大学学术排名第152位THE（2018）泰晤士高等教育世界大学排名第301-350位QS（2018）世界大学排名第236位韦伯麦特里克斯网(Webometrics)世界大学（2018）排名第295名下面是这个学校的校园，是不是很美呐！！！好啦，言归正传！下面介绍：数据结构PDF与配套代码-C语言-严蔚敏小亮将大学上数据结构（C语言）这门课的课件和实验也单独整理出来了，放在一个文件夹中（数据结构PPT），分享给大家！（如果大家觉得不和胃口，可以忽略这个文件夹，直接跳转到下面的文件夹哈。）然后是《数据结构(C语言版).严蔚敏_吴伟民》扫描版PDF和本书的配套代码，如下图所示:一点点感受：其实，数据结构小亮觉得非常重要，他强调逻辑的严密性和算法的高效性。最近小亮的师兄也在找工作——&gt;机器学习方向算法岗，亲身感受到了算法基础的重要性，而算法又不是短期内能够提升的，贵在平时的积累与代码实践，所以小亮特意整理了这些资料，分享给技术小伙伴们！]]></content>
      <categories>
        <category>数据结构 C语言 算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汉字拼音转换工具_Python版]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F03%2F%E6%B1%89%E5%AD%97%E6%8B%BC%E9%9F%B3%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7-Python%E7%89%88%2F</url>
    <content type="text"><![CDATA[环境配置：Wn10+CPU i7-6700Pycharm 2018python 3.6numpy 1.14.5一、github介绍先附上github的一张图片哈：github地址如下：https://github.com/mozillazg/python-pinyin二、特性(1) 根据词组智能匹配最正确的拼音。(2) 支持多音字。(3) 简单的繁体支持, 注音支持。(4) 支持多种不同拼音/注音风格。三、安装注意：以下两种安装方式选择其一即可1、pip安装1$ pip install pypinyin 2、pycharm安装四、代码实践123456789101112131415161718192021222324#coding:utf-8from pypinyin import pinyin, lazy_pinyin, Stylevalue1 = pinyin('天津大学')print(value1)value2 = pinyin('天津大学', heteronym=True) # 启用多音字模式print(value2)value3 = pinyin('天津大学', style=Style.FIRST_LETTER) # 设置拼音风格print(value3)value4 = pinyin('天津大学', style=Style.TONE2, heteronym=True)print(value4)value5 = pinyin('天津大学', style=Style.BOPOMOFO) # 注音风格print(value5)value6 = pinyin('天津大学', style=Style.CYRILLIC) # 俄语字母风格print(value6)value7 = lazy_pinyin('天津大学') # 不考虑多音字的情况print(value7) 五、实验结果1234567[[&apos;tiān&apos;], [&apos;jīn&apos;], [&apos;dà&apos;], [&apos;xué&apos;]][[&apos;tiān&apos;], [&apos;jīn&apos;], [&apos;dà&apos;], [&apos;xué&apos;]][[&apos;t&apos;], [&apos;j&apos;], [&apos;d&apos;], [&apos;x&apos;]][[&apos;tia1n&apos;], [&apos;ji1n&apos;], [&apos;da4&apos;], [&apos;xue2&apos;]][[&apos;ㄊㄧㄢ&apos;], [&apos;ㄐㄧㄣ&apos;], [&apos;ㄉㄚˋ&apos;], [&apos;ㄒㄩㄝˊ&apos;]][[&apos;тянь1&apos;], [&apos;цзинь1&apos;], [&apos;да4&apos;], [&apos;сюэ2&apos;]][&apos;tian&apos;, &apos;jin&apos;, &apos;da&apos;, &apos;xue&apos;]]]></content>
      <categories>
        <category>Python NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018算法工程师秋招集锦]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F09%2F03%2F2018%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%A7%8B%E6%8B%9B%E9%9B%86%E9%94%A6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Learning Pyspark]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F25%2FLearning-Pyspark%2F</url>
    <content type="text"><![CDATA[我把书籍PDF版本和配套代码放在我的百度云里，附上链接地址：百度云链接：https://pan.baidu.com/s/1EogSZ3mT4tAYZyqj6WprIg 密码：vsmv下面介绍一下这本书：Learning Pyspark 感谢您选择本书开始您的PySpark冒险，我希望您像我一样兴奋。当DennyLee第一次告诉我这本新书的时候很高兴 - 使Apache Spark成为最重要的事情之一精彩的平台，支持Java / Scala / JVM世界和Python（以及最近的R）世界。许多以前针对Spark的书都是专注于所有核心语言，或主要关注JVM语言，所以很高兴看到PySpark有机会用这样的专用书来发光经验丰富的Spark教育家。通过支持这两个不同的世界，我们是能够更有效地作为数据科学家和数据工程师一起工作窃取彼此社区的最佳想法。能够有机会审查其早期版本是一种荣幸这本书，只是增加了我对这个项目的兴奋。我有这个特权参加一些相同的会议和聚会，并观看作者向各种受众介绍Spark世界的新概念（从第一部分开始）定时器到老手），他们做了很好的工作，提炼他们的经验这本书。作者的经验从他们的作品中汲取了一切对所涉及主题的解释。除了简单介绍PySpark之外，他们还有还花时间查看来自社区的新闻包，例如GraphFrames和TensorFrames。我认为社区是决定时经常被忽视的组件之一使用什么工具，Python有一个很棒的社区，我很期待您加入了PythonSpark社区。所以，享受你的冒险;我知道你是与Denny Lee和TomekDrabas保持良好关系。我真的相信这一点一个多样化的Spark用户社区，我们将能够制作更好的工具。大家好，所以我希望能在一次会议，聚会或邮寄中见到你很快列出:)霍尔顿卡劳附：我欠丹尼一杯啤酒;如果你想给我买一个Bud Light lime（或lime-a-rita）我非常感激（虽然他可能不像我那样有趣）.本书作者：Tomasz DrabasTomasz Drabas是一名为微软工作的数据科学家，目前居住在微软西雅图地区。 他在数据分析和数据科学方面拥有超过13年的经验在众多的领域：先进技术，航空公司，电信，金融，他在三大洲工作时获得了咨询：欧洲，澳大利亚，和北美。 在澳大利亚期间，Tomasz一直在攻读他的博士学位运营研究，重点关注选择建模和收益管理航空业的应用。]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python之禅]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2FPython%E4%B9%8B%E7%A6%85%2F</url>
    <content type="text"><![CDATA[The Zen of Python, by Tim PetersBeautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.Special cases aren’t special enough to break the rules.Although practicality beats purity.Errors should never pass silently.Unless explicitly silenced.In the face of ambiguity, refuse the temptation to guess.There should be one– and preferably only one –obvious way to do it.Although that way may not be obvious at first unless you’re Dutch.Now is better than never.Although never is often better than right now.If the implementation is hard to explain, it’s a bad idea.If the implementation is easy to explain, it may be a good idea.Namespaces are one honking great idea – let’s do more of those! Tim Peters的Python之禅美丽胜过丑陋。显式优于隐式。简单比复杂更好。复杂比复杂更好。Flat优于嵌套。稀疏优于密集。可读性很重要。特殊情况不足以打破规则。虽然实用性胜过纯洁。错误不应该默默地传递。除非明确沉默。面对模棱两可，拒绝猜测的诱惑。应该有一个 - 最好只有一个 - 显而易见的方法。虽然这种方式起初可能并不明显，除非你是荷兰人。现在总比没有好。虽然现在永远不会比*正确好。如果实施很难解释，那是个坏主意。如果实现很容易解释，那可能是个好主意。命名空间是一个很棒的主意 - 让我们做更多的事情吧！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GAN的理解与TensorFlow的实现]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2FGAN%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8ETensorFlow%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络 高维信息处理 ——2018.7.31于天津大学一、前言本文会从头介绍生成对抗式网络的一些内容，从生成式模型开始说起，到GAN的基本原理，InfoGAN，AC-GAN的基本科普，如果有任何有错误的地方，请随时喷，我刚开始研究GAN这块的内容，希望和大家一起学习。二、生成式模型何为生成式模型？在很多machine learning的教程或者公开课上，通常会把machine learning的算法分为两类： 生成式模型、判别式模型；其区别在于： 对于输入x，类别标签y，在生成式模型中估计其联合概率分布，而判别式模型估计其属于某类的条件概率分布。 常见的判别式模型包括：LogisticRegression， SVM, Neural Network等等，生成式模型包括：Naive Bayes， GMM， Bayesian Network， MRF 等等。三、研究生成式模型的意义生成式模型的特性主要包括以下几个方面： 在应用数学和工程方面，生成式模型能够有效地表征高维数据分布； 生成式模型能够作为一种技术手段辅助强化学习，能够有效表征强化学习模型中的state状态(这里不扩展，后面会跟RL的学习笔记)； 对semi-supervised learning也有比较好的效果，能够在miss data下训练模型，并在miss data下给出相应地输出； 在对于一个输入伴随多个输出的场景下，生成式模型也能够有效工作，而传统的机器学习方法通过最小化模型输出和期望输出的某个object function的值 无法训练单输入多输出的模型，而生成式模型，尤其是GAN能够hold住这种场景，一个典型的应用是通过场景预测video的下一帧。生成式模型一些典型的应用： 图像的超分辨率 iGAN：Generative Visual Manipulation on the Natural Image Manifold 图像转换四、生成式模型族谱上图涵盖了基本的生成式模型的方法，主要按是否需要定义概率密度函数分为：Explicit density modelsexplicit density models 又分为tractable explicit models和逼近的explicit model，怎么理解呢，tractable explicit model通常可以直接通过数学方法来建模求解，而基于逼近的explicit model通常无法直接对数据分布进行建模，可以利用数学里的一些近似方法来做数据建模， 通常基于逼近的explicit model分为确定性（变分方法：如VAE的lower bound）和随机性的方法（马尔科夫链蒙特卡洛方法）。 VAE lower bound： 马尔科夫链蒙特卡洛方法（MCMC），一种经典的基于马尔科夫链的抽样方法，通过多次来拟合分布。比较好的教程：A Beginner’s Guide to Monte Carlo Markov Chain MCMC Analysis, An Introduction to MCMC for Machine Learning.Implicit density models无需定义明确的概率密度函数，代表方法包括马尔科夫链、生成对抗式网络（GAN），该系列方法无需定义数据分布的描述函数。 五、生成对抗式网络与其他生成式网络对比生成对抗式网络（GAN）能够有效地解决很多生成式方法的缺点，主要包括： 并行产生samples； 生成式函数的限制少，如无需合适马尔科夫采样的数据分布（Boltzmann machines），生成式函数无需可逆、latent code需与sample同维度（nonlinear ICA）； 无需马尔科夫链的方法（Boltzmann machines， GSNs）； 相对于VAE的方法，无需variational bound；GAN比其他方法一般来说性能更好。 可以使用冒号来定义对齐方式： 六、GAN工作原理GAN主要由两部分构成：generator和discriminator，generator主要是从训练数据中产生相同分布的samples，而discriminator 则是判断输入是真实数据还是generator生成的数据，discriminator采用传统的监督学习的方法。这里我们可以这样类比，generator 是一个伪造假币的专业人士，discriminator是警察，generator的目的是制造出尽可能以假乱真的假钞，而discriminator是为了能 鉴别是否为假钞，最终整个gan会达到所谓的纳什均衡，Goodfellow在他的paperGAN的理解与TF的实现-小石头的码疯窝中有严格的数学证明，当$p_G$==$p_{data}$时达到 全局最优：另一个比较明显看得懂的图如下：图中黑色点线为真实数据分布$p_{data}$，绿色线为generator生成的数据分布$p_{G}$,而Discriminator就是蓝色点线，其目的是为了将$p_{data}$和$p_{G}$ 区分，(a)中是初始状态，然后会更新Discriminator中的参数，若干次step之后，Discriminator有了较大的判断力即到了(b)的状态，之后会更新G的模型使其生成的数据分布（绿色线）更加趋近与真实数据分布， 若干次G和D的模型参数更新后，理论上最终会达到(d)的状态即G能够产生和真实数据完全一致的分布(证明见上一张图)，如从随机数据分布生成人脸像。七、如何训练GAN因为GAN结构的不同，和常规训练一个dl model方法不同， 这里采用simultaneous SGD，每一个step中，会有两个两个梯度优化的 过程，一个是更新discriminator的参数来最小化$J_{(D)}$，一个是更新generator的参数来最小$J_{(G)}$，通常会选用Adam来作为最优化的优化器， 也有人建议可以不等次数地更新generator和discriminator（有相关工作提出，1：1的在实际中更有效：Adam: A Method for Stochastic Optimization） 如何训练GAN，在Goodfellow的GAN的tutorial还有一些代码中有更多的描述包括不同的cost function， 这里我就不详细展开了。1、DCGANGAN出来后很多相关的应用和方法都是基于DCGAN的结构，DCGAN即”Deep Convolution GAN”，通常会有一些约定俗成的规则： 在Discriminator和generator中大部分层都使用batch normalization，而在最后一层时通常不会使用batch normalizaiton，目的 是为了保证模型能够学习到数据的正确的均值和方差； 因为会从random的分布生成图像，所以一般做需要增大图像的空间维度时如77-&gt;1414， 一般会使用strdie为2的deconv（transposed convolution）； 通常在DCGAN中会使用Adam优化算法而不是SGD。2、各种GAN这里有个大神把各种gan的paper都做了一个统计AdversarialNetsPapers这里大家有更多的兴趣可以直接去看对应的paper，我接下来会尽我所能描述下infogan和AC-GAN这两块的内容3、InfoGANInfoGAN是一种能够学习disentangled representation的GAN，何为disentangled representation？比如人脸数据集中有各种不同的属性特点，如脸部表情、是否带眼睛、头发的风格眼珠的颜色等等，这些很明显的相关表示， InfoGAN能够在完全无监督信息（是否带眼睛等等）下能够学习出这些disentangled representation，而相对于传统的GAN，只需修改loss来最大化GAN的input的noise（部分fixed的子集）和最终输出之间的互信息。4、原理为了达到上面提到的效果，InfoGAN必须在input的noise来做一些文章，将noise vector划分为两部分： z: 和原始的GAN input作用一致； c: latent code，能够在之后表示数据分布中的disentangled representation那么如何从latent code中学到相应的disentangled representation呢？ 在原始的GAN中，忽略了c这部分的影响，即GAN产生的数据分布满足$P_{G}(x|C)=P(x)$,为了保证能够利用c这部分信息， 作者提出这样一个假设：c与generator的输出相关程度应该很大，而在信息论中，两个数据分布的相关程度即互信息， 即generator的输出和input的c的$I(c;G(z,c))$应该会大。 所以，InfoGAN就变成如下的优化问题：因为互信息的计算需要后验概率的分布（下图红线部分），在实际中很难直接使用，因此，在实际训练中一般不会直接最大化$I(c;G(z,c))$这里作者采用和VAE类似的方法，增加一个辅助的数据分布为后验概率的low bound： 所以，这里互信息的计算如下：这里相关的证明就不深入了，有兴趣的可以去看看paper。5、实验我写的一版基于TensorFlow的Info-GAN实现：Info-GANburness/tensorflow-101 random的label信息，和对应生成的图像：不同random变量控制产生同一class下的不同输出：6、AC-GANAC-GAN即auxiliary classifier GAN，对应的paper：[1610.09585] Conditional Image Synthesis With Auxiliary Classifier GANs, 如前面的示意图中所示，AC-GAN的Discriminator中会输出相应的class label的概率，然后更改loss fuction，增加class预测正确的概率， ac-gan是一个tensorflow相关的实现，基于作者自己开发的sugartensor，感觉和paper里面在loss函数的定义上差异，看源码的时候注意下，我这里有参考写了一个基于原生tensorflow的版本AC-GAN.实验各位有兴趣的可以拿代码在其他的数据集上也跑一跑，AC-GAN能够有效利用class label的信息，不仅可以在G时指定需要生成的image的label，同事该class label也能在Discriminator用来扩展loss函数，增加整个对抗网络的性能。 random的label信息，和对应生成的图像：不同random变量控制产生同一class下的不同输出：七、总结照例总结一下，本文中，我基本介绍了下生成式模型方法的各个族系派别，到GAN的基本内容，到InfoGAN、AC-GAN，大部分的工作都来自于阅读相关的paper，自己相关的工作就是 tensorflow下参考sugartensor的内容重现了InfoGAN、AC-GAN的相关内容。当然，本人菜鸟一枚，难免有很多理解不到位的地方，写出来更多的是作为分享，让更多人了解GAN这块的内容，如果任何错误或不合适的地方，敬请在评论中指出，我们一起讨论一起学习 另外我的所有相关的代码都在github上:GAN,相信读一下无论是对TensorFlow的理解还是GAN的理解都会 有一些帮助，简单地参考mnist.py修改下可以很快的应用到你的数据集上，如果有小伙伴在其他数据集上做出有意思的实验效果的，欢迎分享。 原文地址： http://www.leiphone.com/news/201702/GZsIbIb9V9AUGmb6.html]]></content>
      <categories>
        <category>Tensorflow实战深度学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于深度学习tensorflow实现文本分类任务的注意力机制]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2FTensorflow%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8ERNN%E7%9A%84%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[要点：该教程为深度学习tensorflow实现文本分类任务的注意力机制，实现可视化注意力文本。环境配置：Wn10+CPU i7-6700Pycharm2018Tensorflow 1.8.0Tensorboard 1.8.0笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络 ——2018.8.8于天津大学 一、下载代码 该代码见笔者的资源下载部分https://download.csdn.net/download/jinyuan7708/10592063 代码不需要改动，只需要配置好环境和安装好相应的库，就可以训练和测试了。二、相应的库文件 tensorflow 1.8.0 tensorboard 1.8.0 numpy keras tqdm三、工程目录文件 该项目主要包括attention.py train.py utils.py visualize.py四个文件夹 其中train.py文件是训练模型的文件，运行后会生成model.data-00000-of-00001、model.index、model.meta以及checkpoint文件，也就是训练生成的模型文件。四、核心代码train.py文件代码 from __future__ import print_function, division import numpy as np import tensorflow as tf from keras.datasets import imdb from tensorflow.contrib.rnn import GRUCell from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn as bi_rnn from tqdm import tqdm from attention import attention from utils import get_vocabulary_size, fit_in_vocabulary, zero_pad, batch_generator NUM_WORDS = 10000 INDEX_FROM = 3 SEQUENCE_LENGTH = 250 EMBEDDING_DIM = 100 HIDDEN_SIZE = 150 ATTENTION_SIZE = 50 KEEP_PROB = 0.8 BATCH_SIZE = 256 NUM_EPOCHS = 3 # Model easily overfits without pre-trained words embeddings, that&apos;s why train for a few epochs DELTA = 0.5 MODEL_PATH = &apos;./model&apos; # Load the data set (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM) # Sequences pre-processing vocabulary_size = get_vocabulary_size(X_train) X_test = fit_in_vocabulary(X_test, vocabulary_size) X_train = zero_pad(X_train, SEQUENCE_LENGTH) X_test = zero_pad(X_test, SEQUENCE_LENGTH) # Different placeholders with tf.name_scope(&apos;Inputs&apos;): batch_ph = tf.placeholder(tf.int32, [None, SEQUENCE_LENGTH], name=&apos;batch_ph&apos;) target_ph = tf.placeholder(tf.float32, [None], name=&apos;target_ph&apos;) seq_len_ph = tf.placeholder(tf.int32, [None], name=&apos;seq_len_ph&apos;) keep_prob_ph = tf.placeholder(tf.float32, name=&apos;keep_prob_ph&apos;) # Embedding layer with tf.name_scope(&apos;Embedding_layer&apos;): embeddings_var = tf.Variable(tf.random_uniform([vocabulary_size, EMBEDDING_DIM], -1.0, 1.0), trainable=True) tf.summary.histogram(&apos;embeddings_var&apos;, embeddings_var) batch_embedded = tf.nn.embedding_lookup(embeddings_var, batch_ph) # (Bi-)RNN layer(-s) rnn_outputs, _ = bi_rnn(GRUCell(HIDDEN_SIZE), GRUCell(HIDDEN_SIZE), inputs=batch_embedded, sequence_length=seq_len_ph, dtype=tf.float32) tf.summary.histogram(&apos;RNN_outputs&apos;, rnn_outputs) # Attention layer with tf.name_scope(&apos;Attention_layer&apos;): attention_output, alphas = attention(rnn_outputs, ATTENTION_SIZE, return_alphas=True) tf.summary.histogram(&apos;alphas&apos;, alphas) # Dropout drop = tf.nn.dropout(attention_output, keep_prob_ph) # Fully connected layer with tf.name_scope(&apos;Fully_connected_layer&apos;): W = tf.Variable(tf.truncated_normal([HIDDEN_SIZE * 2, 1], stddev=0.1)) # Hidden size is multiplied by 2 for Bi-RNN b = tf.Variable(tf.constant(0., shape=[1])) y_hat = tf.nn.xw_plus_b(drop, W, b) y_hat = tf.squeeze(y_hat) tf.summary.histogram(&apos;W&apos;, W) with tf.name_scope(&apos;Metrics&apos;): # Cross-entropy loss and optimizer initialization loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_hat, labels=target_ph)) tf.summary.scalar(&apos;loss&apos;, loss) optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss) # Accuracy metric accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(tf.sigmoid(y_hat)), target_ph), tf.float32)) tf.summary.scalar(&apos;accuracy&apos;, accuracy) merged = tf.summary.merge_all() train_batch_generator = batch_generator(X_train, y_train, BATCH_SIZE) test_batch_generator = batch_generator(X_test, y_test, BATCH_SIZE) train_writer = tf.summary.FileWriter(&apos;./logdir/train&apos;, accuracy.graph) test_writer = tf.summary.FileWriter(&apos;./logdir/test&apos;, accuracy.graph) session_conf = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)) saver = tf.train.Saver() if __name__ == &quot;__main__&quot;: with tf.Session(config=session_conf) as sess: sess.run(tf.global_variables_initializer()) print(&quot;Start learning...&quot;) for epoch in range(NUM_EPOCHS): loss_train = 0 loss_test = 0 accuracy_train = 0 accuracy_test = 0 print(&quot;epoch: {}\t&quot;.format(epoch), end=&quot;&quot;) # Training num_batches = X_train.shape[0] // BATCH_SIZE for b in tqdm(range(num_batches)): x_batch, y_batch = next(train_batch_generator) seq_len = np.array([list(x).index(0) + 1 for x in x_batch]) # actual lengths of sequences loss_tr, acc, _, summary = sess.run([loss, accuracy, optimizer, merged], feed_dict={batch_ph: x_batch, target_ph: y_batch, seq_len_ph: seq_len, keep_prob_ph: KEEP_PROB}) accuracy_train += acc loss_train = loss_tr * DELTA + loss_train * (1 - DELTA) train_writer.add_summary(summary, b + num_batches * epoch) accuracy_train /= num_batches # Testing num_batches = X_test.shape[0] // BATCH_SIZE for b in tqdm(range(num_batches)): x_batch, y_batch = next(test_batch_generator) seq_len = np.array([list(x).index(0) + 1 for x in x_batch]) # actual lengths of sequences loss_test_batch, acc, summary = sess.run([loss, accuracy, merged], feed_dict={batch_ph: x_batch, target_ph: y_batch, seq_len_ph: seq_len, keep_prob_ph: 1.0}) accuracy_test += acc loss_test += loss_test_batch test_writer.add_summary(summary, b + num_batches * epoch) accuracy_test /= num_batches loss_test /= num_batches print(&quot;loss: {:.3f}, val_loss: {:.3f}, acc: {:.3f}, val_acc: {:.3f}&quot;.format( loss_train, loss_test, accuracy_train, accuracy_test )) train_writer.close() test_writer.close() saver.save(sess, MODEL_PATH) print(&quot;Run &apos;tensorboard --logdir=./logdir&apos; to checkout tensorboard logs.&quot;) 五、训练过程 笔者由于使用的 CPU来进行训练，所以速度比较慢，感兴趣的朋友可以考虑使用GPU来计算，可以大大减少训练模型的时间。如果不会搭建gpu环境的小伙伴可以参考我的另一篇Tensorflow gpu环境搭建 ，附上地址哈： https://blog.csdn.net/jinyuan7708/article/details/79642924六、训练结果 七、Tensorboard可视化八、visualization可视化结果得到模型后，再继续执行visualize.py文件，生成结果可视化。如下图：至此，我们的教程就结束啦，代码等文件我上传到我的blog下载资源部分，欢迎大家下载批评指正哈!代码地址：https://download.csdn.net/download/jinyuan7708/10592063]]></content>
      <categories>
        <category>Tensorflow实战深度学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中英文NLP集成型工具汇总]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2F%E4%B8%AD%E8%8B%B1%E6%96%87NLP%E9%9B%86%E6%88%90%E5%9E%8B%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[该文档简单总结了一下集成的中英文NLP工具，分享给NLP领域的大家！笔者信息：Next_Legend QQ:1219154092 机器学习 自然语言处理 计算机视觉 深度学习——2018.8.19于天津大学 1、面向研究的StanfordNLP(Java) (CoreNLP/Parder/POS Tager/NER…) 网页链接2、面向应用的SpaCy(Python) 网页链接3、哈工大语言技术平台LTP(C++) 网页链接4、本土的HanLP(Java) 网页链接5、轻量非主流的xmnlp(Python) 网页链接6、相对零散的THUNLP开放项目 网页链接7、复旦大学NLP 网页链接8、清华大学NLP 网页链接9、TEXTBLOG 网页链接10、PyNLPIR 网页链接11、Polyglot 网页链接12、NLTK 网页链接其他的NLP工具小编暂时没有了解，欢迎有使用经验的同学朋友补充！]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法_NLP_深度学习_机器学习面试笔记]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2F%E7%AE%97%E6%B3%95_NLP_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[笔者信息：Next_Legend QQ:1219154092 机器学习 自然语言处理 图像处理 深度学习——2018.8.13于天津大学 GitHub 地址：https://github.com/imhuay/CS_Interview_Notes-Chinese深度学习/机器学习面试问题整理，想法来源于这个仓库. - 该仓库整理了“花书”《深度学习》中的一些常见问题，其中部分偏理论的问题没有收录，如有需要可以浏览原仓库。此外，还包括我看到的所有机器学习/深度学习面经中的问题。除了其中 DL/ML 相关的，其他与算法岗相关的计算机知识也会记录。但是不会包括如前端/测试/JAVA/Android等岗位中有关的问题。RoadMap数学 微积分的本质深度学习的核心自然语言处理 词向量 Word2VecGloVeFastTextWordRank TODO序列建模 TODO工具库机器学习-深度学习 公共基础 背景知识损失函数深度学习 深度学习基础《深度学习》整理CNN专题机器学习 机器学习算法机器学习实践算法 题解-剑指Offer编程语言 Cpp专题-基础知识Cpp专题-左值与右值笔试面经项目经验code 工具库 gensim.FastText 的使用倒排索引Tensorflow 基础 TODO各公司招聘要求必备清单 TODO深度学习 反向传播算法梯度下降法深度学习实践（项目经验）相关代码 TODO机器学习算法 逻辑斯蒂回归支持向量机AdaBoost 算法GBDT 梯度提升决策树相关代码 TODO计算机基础 必背算法Python 常识 TODOC++ 常识 TODO欢迎分享你在深度学习/机器学习面试过程中遇见的问题！你可以直接以你遇到的问题作为 issue 标题，然后分享你的回答或者其他参考资料。当然，你也可以直接创建 PR，分享问题的同时改正我的错误！ 我会经常修改文档的结构（特别是代码的链接）。如果文中有链接失效，请告诉我！ 文档中大部分链接都是指向仓库内的文件或标记；涉及编程代码的链接会指向我的另一个仓库（Algorithm_for_Interview）Referenceexacity/deeplearningbook-chinese: 深度学习中文版 elviswf/DeepLearningBookQA_cn: 深度学习面试问题 回答对应的DeepLearning中文版页码huihut/interview: C/C++面试知识总结 七月在线：结构之法 算法之道 - CSDN博客在线 LaTeX 公式编辑器 http://www.codecogs.com/latex/eqneditor.phpGitHub 搜索：Deep Learning InterviewGitHub 搜索：Machine Learning Interview geekcircle/machine-learning-interview-qa: 人工智能-机器学习笔试面试题解析 牛客网-讨论区]]></content>
      <categories>
        <category>面试集锦</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于python+opencv的图像目标区域自动提取]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2F%E5%9F%BA%E4%BA%8Epython%2Bopencv%E7%9A%84%E5%9B%BE%E5%83%8F%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E8%87%AA%E5%8A%A8%E6%8F%90%E5%8F%96%EF%BC%88%E6%9C%AC%E9%A1%B9%E7%9B%AE%E4%B8%BA%E6%8F%90%E5%8F%96%E7%BA%B8%E5%BC%A0%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%89%2F</url>
    <content type="text"><![CDATA[要点：该教程为基于python+opencv的图像目标区域自动提取，实现自动提取一张照片中的纸张内容环境配置：Wn10+CPU i7-6700Pycharm2018opencv-python 3.4.2.17numpy 1.14.5笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络 ——2018.8.12于天津大学 该项目的代码在笔者的资源仓库中，代码地址：基于python+opencv的图像目标区域自动提取 一、项目背景一张照片中的感兴趣区域总是沿着x,y,z三个轴都有一定倾斜（如下图），要想把照片翻转到平行位置，需要进行透视变换，而透视变换需要同一像素点变换前后的坐标。由此可以想到，提取矩形区域四个角的坐标作为变换前的坐标，变换后的坐标可以设为照片的四个角落，经过投影变换，矩形区域将会翻转并充满图像。因此我们要解决的问题变为：提取矩形的四个角落、进行透视变换。 二、提取矩形角落坐标矩形的检测主要是提取边缘，图片显示部分的亮度通常高于周围环境，我们可以将图片阈值化，将图片部分与周围环境明显的分别开来，这对后边的边缘检测非常有帮助。检测矩形并提取坐标需要对图像进行预处理、边缘检测、提取轮廓、检测凸包、角点检测。1、预处理转为灰度图由于手机拍摄的照片像素可能会很高，为了加快处理速度，我们首先将图像转化为灰度图1234image = cv2.imread(Config.src)gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)srcWidth, srcHeight, channels = image.shapeprint(srcWidth, srcHeight) 2、中值滤波 1binary = cv2.medianBlur(gray,7) 3、转化为二值图像12ret, binary = cv2.threshold(binary, Config.threshold_thresh, 255, cv2.THRESH_BINARY)cv2.imwrite("1-threshold.png", binary, [int(cv2.IMWRITE_PNG_COMPRESSION), 9]) 此时图片已经变成了这个样子：可见纸张页面部分已经与背景环境分离开来。4、边缘检测与轮廓处理我们用Canny算子边缘检测，提取轮廓 123# canny提取轮廓binary = cv2.Canny(binary, 0, 60, apertureSize = 3)cv2.imwrite("3-canny.png", binary, [int(cv2.IMWRITE_PNG_COMPRESSION), 9]) 提取轮廓后，拟合外接多边形（矩形） 123# 提取轮廓后，拟合外接多边形（矩形）_,contours,_ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)print("len(contours)=%d"%(len(contours))) 5、提取面积最大的轮廓并用多边形将轮廓包围 123456789101112131415161718192021222324252627282930313233343536373839404142for idx,c in enumerate(contours): if len(c) &lt; Config.min_contours: continue epsilon = Config.epsilon_start while True: approx = cv2.approxPolyDP(c,epsilon,True) print("idx,epsilon,len(approx),len(c)=%d,%d,%d,%d"%(idx,epsilon,len(approx),len(c))) if (len(approx) &lt; 4): break if math.fabs(cv2.contourArea(approx)) &gt; Config.min_area: if (len(approx) &gt; 4): epsilon += Config.epsilon_step print("epsilon=%d, count=%d"%(epsilon,len(approx))) continue else: #for p in approx: # cv2.circle(binary,(p[0][0],p[0][1]),8,(255,255,0),thickness=-1) approx = approx.reshape((4, 2)) # 点重排序, [top-left, top-right, bottom-right, bottom-left] src_rect = order_points(approx) cv2.drawContours(image, c, -1, (0,255,255),1) cv2.line(image, (src_rect[0][0],src_rect[0][1]),(src_rect[1][0],src_rect[1][1]),color=(100,255,100)) cv2.line(image, (src_rect[2][0],src_rect[2][1]),(src_rect[1][0],src_rect[1][1]),color=(100,255,100)) cv2.line(image, (src_rect[2][0],src_rect[2][1]),(src_rect[3][0],src_rect[3][1]),color=(100,255,100)) cv2.line(image, (src_rect[0][0],src_rect[0][1]),(src_rect[3][0],src_rect[3][1]),color=(100,255,100)) # 获取最小矩形包络 rect = cv2.minAreaRect(approx) # rect = cv2.maxAreaRect(approx) box = cv2.boxPoints(rect) box = np.int0(box) box = box.reshape(4,2) box = order_points(box) print("approx-&gt;box") print(approx) print(src_rect) print(box) w,h = point_distance(box[0],box[1]), \ point_distance(box[1],box[2]) print("w,h=%d,%d"%(w,h)) 6、 透视变换 12345678910dst_rect = np.array([ [0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype="float32") M = cv2.getPerspectiveTransform(src_rect, dst_rect) warped = cv2.warpPerspective(image, M, (w, h)) cv2.imwrite("transfer%d.png"%idx, warped, [int(cv2.IMWRITE_PNG_COMPRESSION), 9]) break 总结本项目利用了照片背景亮度较高的特点，通过二值化突出轮廓提取坐标，进行透视变换。但是局限性在于，如果矩形的亮度与背景相差不大，就很难用这种方法检测到轮廓还需要算法优化。该项目的代码在笔者的资源仓库中，代码地址：基于python+opencv的图像目标区域自动提取]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于Kears的Attention实战]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2F%E5%9F%BA%E4%BA%8EKeras%E7%9A%84attention%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[要点：该教程为基于Kears的Attention实战，环境配置：Wn10+CPU i7-6700Pycharm 2018python 3.6numpy 1.14.5Keras 2.0.2Matplotlib 2.2.2强调：各种库的版本型号一定要配置对，因为Keras以及Tensorflow升级更新比较频繁，很多函数更新后要么更换了名字，要么没有这个函数了，所以大家务必重视。相关代码我放在了我的代码仓库里哈，欢迎大家下载，这里附上地址：基于Kears的Attention实战笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络——2018.8.21于天津大学 一、导读最近两年，尤其在今年，注意力机制(Attention)及其变种Attention逐渐热了起来，在很多顶会Paper中都或多或少的用到了attention,所以小编出于好奇，整理了这篇基于Kears的Attention实战，本教程仅从代码的角度来看Attention。通过一个简单的例子，探索Attention机制是如何在模型中起到特征选择作用的。二、代码实战（一）1、导入相关库文件1234567import numpy as npfrom attention_utils import get_activations, get_datanp.random.seed(1337) # for reproducibilityfrom keras.models import *from keras.layers import Input, Dense, mergeimport tensorflow as tf 2、数据生成函数 1234567891011121314def get_data(n, input_dim, attention_column=1): """ Data generation. x is purely random except that it's first value equals the target y. In practice, the network should learn that the target = x[attention_column]. Therefore, most of its attention should be focused on the value addressed by attention_column. :param n: the number of samples to retrieve. :param input_dim: the number of dimensions of each element in the series. :param attention_column: the column linked to the target. Everything else is purely random. :return: x: model inputs, y: model targets """ x = np.random.standard_normal(size=(n, input_dim)) y = np.random.randint(low=0, high=2, size=(n, 1)) x[:, attention_column] = y[:, 0] return x, y 3、模型定义函数将输入进行一次变换后，计算出Attention权重，将输入乘上Attention权重，获得新的特征。123456789101112def build_model(): inputs = Input(shape=(input_dim,)) # ATTENTION PART STARTS HERE attention_probs = Dense(input_dim, activation='softmax', name='attention_vec')(inputs) attention_mul =merge([inputs, attention_probs], output_shape=32, name='attention_mul', mode='mul') # ATTENTION PART FINISHES HERE attention_mul = Dense(64)(attention_mul) output = Dense(1, activation='sigmoid')(attention_mul) model = Model(input=[inputs], output=output) return model 4、主函数12345678910111213141516171819202122232425262728if __name__ == '__main__': N = 10000 inputs_1, outputs = get_data(N, input_dim) m = build_model() m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) print(m.summary()) m.fit([inputs_1], outputs, epochs=20, batch_size=64, validation_split=0.5) testing_inputs_1, testing_outputs = get_data(1, input_dim) # Attention vector corresponds to the second matrix. # The first one is the Inputs output. attention_vector = get_activations(m, testing_inputs_1, print_shape_only=True, layer_name='attention_vec')[0].flatten() print('attention =', attention_vector) # plot part. import matplotlib.pyplot as plt import pandas as pd pd.DataFrame(attention_vector, columns=['attention (%)']).plot(kind='bar', title='Attention Mechanism as ' 'a function of input' ' dimensions.') plt.show() 5、运行结果代码中，attention_column为1，也就是说，label只与数据的第1个特征相关。从运行结果中可以看出，Attention权重成功地获取了这个信息。 三、代码实战（二）1、导入相关库文件1234567891011from keras.layers import mergefrom keras.layers.core import *from keras.layers.recurrent import LSTMfrom keras.models import *from attention_utils import get_activations, get_data_recurrentINPUT_DIM = 2TIME_STEPS = 20# if True, the attention vector is shared across the input_dimensions where the attention is applied.SINGLE_ATTENTION_VECTOR = FalseAPPLY_ATTENTION_BEFORE_LSTM = False 2、数据生成函数 12345678910111213141516171819202122232425262728293031def attention_3d_block(inputs): # inputs.shape = (batch_size, time_steps, input_dim) input_dim = int(inputs.shape[2]) a = Permute((2, 1))(inputs) a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what. a = Dense(TIME_STEPS, activation='softmax')(a) if SINGLE_ATTENTION_VECTOR: a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a) a = RepeatVector(input_dim)(a) a_probs = Permute((2, 1), name='attention_vec')(a) output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul') return output_attention_mul def model_attention_applied_after_lstm(): inputs = Input(shape=(TIME_STEPS, INPUT_DIM,)) lstm_units = 32 lstm_out = LSTM(lstm_units, return_sequences=True)(inputs) attention_mul = attention_3d_block(lstm_out) attention_mul = Flatten()(attention_mul) output = Dense(1, activation='sigmoid')(attention_mul) model = Model(input=[inputs], output=output) return modeldef model_attention_applied_before_lstm(): inputs = Input(shape=(TIME_STEPS, INPUT_DIM,)) attention_mul = attention_3d_block(inputs) lstm_units = 32 attention_mul = LSTM(lstm_units, return_sequences=False)(attention_mul) output = Dense(1, activation='sigmoid')(attention_mul) model = Model(input=[inputs], output=output) return model 3、主函数12345678910111213141516171819202122232425262728293031323334353637if __name__ == '__main__': N = 300000 # N = 300 -&gt; too few = no training inputs_1, outputs = get_data_recurrent(N, TIME_STEPS, INPUT_DIM) if APPLY_ATTENTION_BEFORE_LSTM: m = model_attention_applied_before_lstm() else: m = model_attention_applied_after_lstm() m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) print(m.summary()) m.fit([inputs_1], outputs, epochs=1, batch_size=64, validation_split=0.1) attention_vectors = [] for i in range(300): testing_inputs_1, testing_outputs = get_data_recurrent(1, TIME_STEPS, INPUT_DIM) attention_vector = np.mean(get_activations(m, testing_inputs_1, print_shape_only=True, layer_name='attention_vec')[0], axis=2).squeeze() print('attention =', attention_vector) assert (np.sum(attention_vector) - 1.0) &lt; 1e-5 attention_vectors.append(attention_vector) attention_vector_final = np.mean(np.array(attention_vectors), axis=0) # plot part. import matplotlib.pyplot as plt import pandas as pd pd.DataFrame(attention_vector_final, columns=['attention (%)']).plot(kind='bar', title='Attention Mechanism as ' 'a function of input' ' dimensions.') plt.show() 4、运行结果代码中，attention_column为10，11，也就是说，label只与数据的第10，11个特征相关。从运行结果中可以看出，Attention权重成功地获取了这个信息。 ##相关代码放在代码仓库里哈，欢迎大家下载，这里附上地址：基于Kears的Attention实战]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[new Types]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2Fnew-Types%2F</url>
    <content type="text"><![CDATA[我的分类是深度学习]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[“test”]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2F%E2%80%9Ctest%E2%80%9D%2F</url>
    <content type="text"><![CDATA[大家好，这是我的第一个hexo!]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2FsliderSun.github.io%2F2018%2F08%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
